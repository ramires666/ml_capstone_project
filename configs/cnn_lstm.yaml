# =============================================================================
# CNN-LSTM Advanced Model Configuration
# =============================================================================
# 
# This configuration file defines all parameters for the CNN-LSTM neural network.
# The architecture combines Convolutional and LSTM layers for sequence modeling.
#
# Usage:
#   python -m src.models.train --config configs/cnn_lstm.yaml
#
# =============================================================================

# -----------------------------------------------------------------------------
# Model Type
# -----------------------------------------------------------------------------
model:
  type: cnn_lstm  # Options: 'xgboost' or 'cnn_lstm'

# -----------------------------------------------------------------------------
# Data Settings
# -----------------------------------------------------------------------------
data:
  train_start: "2024-01-01"
  train_end: "2025-06-30"
  test_start: "2025-07-01"
  test_end: "2025-12-31"

# -----------------------------------------------------------------------------
# Target Label Settings (Oracle)
# -----------------------------------------------------------------------------
labeling:
  sigma: 3              # Gaussian smoothing window
  threshold: 0.0002     # Classification threshold
  n_classes: 3          # UP/SIDEWAYS/DOWN

# -----------------------------------------------------------------------------
# Feature Settings
# -----------------------------------------------------------------------------
features:
  # Prediction horizon
  horizon: 1
  
  # Lookback window for LSTM sequences
  # This is how many previous timesteps the model "sees"
  # Higher values = more context but more memory/computation
  lookback: 10  # 10 showed better results than 32 in notebook experiments
  
  # Feature groups (fewer groups for neural network to prevent overfitting)
  groups:
    - momentum
    - overlap
    - trend
    - volatility
    - volume
    - statistics

# -----------------------------------------------------------------------------
# CNN-LSTM Architecture
# -----------------------------------------------------------------------------
architecture:
  # Conv1D layer settings
  # Kernel extracts local patterns in the time series
  conv_filters: 64      # Number of convolutional filters
  kernel_size: 3        # Size of 1D convolution kernel
  
  # LSTM layer settings
  # LSTMs capture long-term dependencies in sequences
  lstm_units: 64        # Units in first LSTM layer (second layer = 2x)
  
  # Regularization
  # Dropout helps prevent overfitting by randomly zeroing neurons
  dropout: 0.3          # Dropout rate (0.3-0.6 typical)
  
  # Dense layer before output
  dense_units: 32       # Units in fully-connected layer

# -----------------------------------------------------------------------------
# Training Settings
# -----------------------------------------------------------------------------
training:
  # Maximum training epochs
  # Training will stop early if validation loss doesn't improve
  epochs: 30
  
  # Batch size
  # Larger batches = faster training but may generalize worse
  batch_size: 128
  
  # Early stopping patience
  # Stop if validation loss doesn't improve for this many epochs
  patience: 5
  
  # Learning rate for Adam optimizer
  # Lower = slower but more stable, higher = faster but may overshoot
  learning_rate: 0.0007
  
  # Device: 'cuda' for GPU, 'cpu' for CPU
  device: cuda
  
  # Random seed for reproducibility
  random_seed: 42

# -----------------------------------------------------------------------------
# Output Settings
# -----------------------------------------------------------------------------
output:
  model_dir: models_artifacts
  reports_dir: reports
